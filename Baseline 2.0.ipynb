{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "import math\n",
    "import string\n",
    "import os\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Similarity:\n",
    "    def __init__(self, alpha=1.0, beta=1e-3, theta=-1.0):\n",
    "        self.stemmer = PorterStemmer()\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.theta = theta\n",
    "        self.item_num = 0\n",
    "\n",
    "    def change_parameters(self, alpha, beta, theta):\n",
    "        '''change parameter when doing cross validation'''\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.theta = theta\n",
    "\n",
    "    def get_parameters(self):\n",
    "        return self.alpha, self.beta, self.theta\n",
    "\n",
    "    def read_data(self, dataframe):\n",
    "        '''read in the data and fill the NaN'''\n",
    "        # self.data = dataframe\n",
    "        # self.generate_item_vector()\n",
    "        # print(self.data.head(3))\n",
    "        self.data = dataframe\n",
    "        # self.data['description'].fillna(\"\", inplace=True)\n",
    "        # self.data['title'].fillna(\"\", inplace=True)\n",
    "        # self.data['price'].fillna(0, inplace=True)\n",
    "        self.generate_item_vector()\n",
    "\n",
    "    def stem_tokens(self, tokens, stemmer):\n",
    "        '''stemming'''\n",
    "        stemmed = []\n",
    "        for item in tokens:\n",
    "            stemmed.append(stemmer.stem(item))\n",
    "        return stemmed\n",
    "\n",
    "    def tokenize(self, text):\n",
    "        '''do stemming for each word'''\n",
    "        tokens = nltk.word_tokenize(text)\n",
    "        stems = self.stem_tokens(tokens, self.stemmer)\n",
    "        return stems\n",
    "\n",
    "    def data_preprocess(self, corpus):\n",
    "        ''' stop-word filtering and stemming\n",
    "            input: every element represent a title/description of an item (after preprocessing)\n",
    "            corpus = [  \n",
    "                'This is the first document.',  \n",
    "                'This is the second second document.',  \n",
    "                'And the third one.',  \n",
    "                'Is this the first document?',  \n",
    "            ]\n",
    "        '''\n",
    "        token_lst = []\n",
    "        for ele in corpus:\n",
    "            lowers = ele.lower()\n",
    "            #### delete punctuation in string ####\n",
    "            table = str.maketrans(dict.fromkeys(string.punctuation))\n",
    "            no_punctuation = lowers.translate(table)\n",
    "            token_lst.append(no_punctuation)\n",
    "        return token_lst\n",
    "\n",
    "\n",
    "    def cal_tf_idf(self, corpus):\n",
    "        ''' \n",
    "            output: tf-idf value vectors of each element\n",
    "            tf-idf = [[ 0.          0.43877674  0.54197657  0.43877674  0.          0.\t\t\t0.35872874  0.          0.43877674]\n",
    "                      [ 0.          0.27230147  0.          0.27230147  0.          0.85322574\t0.22262429  0.          0.27230147]\n",
    "                      [ 0.55280532  0.          0.          0.          0.55280532  0.\t\t\t0.28847675  0.55280532  0.        ]\n",
    "                      [ 0.          0.43877674  0.54197657  0.43877674  0.          0.\t\t\t0.35872874  0.          0.43877674]]\n",
    "        '''\n",
    "        # print self.token_lst\n",
    "        tfidf = TfidfVectorizer(tokenizer=self.tokenize, stop_words='english')\n",
    "        tfs = tfidf.fit_transform(corpus)\n",
    "        return tfs\n",
    "\n",
    "    def generate_item_vector(self):\n",
    "        ''' Generate item vector for training data\n",
    "            item vector: <et, ed, price>\n",
    "            et: <tf-idf1, tf-idf2, ..., tf-idfk>\n",
    "            ed: <tf-idf1, tf-idf2, ..., tf-idfk>\n",
    "            price: normalized price\n",
    "            self.item_vector_set:\n",
    "                dict {\n",
    "                    '0001': {\n",
    "                        'title': []\n",
    "                        'description': []\n",
    "                        'price': float\n",
    "                    }\t\n",
    "                    '0002': {\n",
    "                        ...\n",
    "                    }\n",
    "                    ...\n",
    "                }\n",
    "        '''\n",
    "        #### original data ####\n",
    "        price_list = np.array(self.data['price']).tolist()\n",
    "        number_list = np.array(self.data['asin']).tolist()\n",
    "        #### tf-idf result ####\n",
    "        self.title_result = self.cal_tf_idf(self.data_preprocess(np.array(self.data['title']).tolist()))\n",
    "        '''\n",
    "        self.title_result:\n",
    "                v1 v2 v3 ... vn\n",
    "            v1\n",
    "            v2\n",
    "            v3\n",
    "            ...\n",
    "            vn \n",
    "        '''\n",
    "        self.title_result = cosine_similarity(self.title_result, self.title_result)\n",
    "        self.description_result = self.cal_tf_idf(self.data_preprocess(np.array(self.data['description']).tolist()))\n",
    "        '''\n",
    "        self.description_result:\n",
    "                v1 v2 v3 ... vn\n",
    "            v1\n",
    "            v2\n",
    "            v3\n",
    "            ...\n",
    "            vn \n",
    "        '''\n",
    "        self.description_result = cosine_similarity(self.description_result, self.description_result)\n",
    "        #### price result ####\n",
    "        '''self.price_result: [p1, p2, p3, ... , pn]'''\n",
    "        self.price_result = [1.0 / (1+math.exp(-self.beta*(price_list[i]))) for i in range(len(price_list))]\n",
    "\n",
    "        self.item_num = len(price_list)\n",
    "        self.item_vector_set = {n:{'title':t, 'description':d, 'price':p} for n,t,d,p in zip(number_list, self.title_result, self.description_result, self.price_result)}\n",
    "\n",
    "    # def generate_item_vector_for_newitem(self, new_item):\n",
    "    # \t''' Generate item vector for new item\n",
    "    # \t\tInput:\n",
    "    # \t\t\tnew_item: dataframe\n",
    "    # \t\tOutput:\n",
    "    # \t\t\tnewitem_title_result[0]: list [v1, v2, v3, ....]\n",
    "    # \t\t\tnewitem_description_result[0]: list [v1, v2, v3, ....]\n",
    "    # \t\t\tprice_result: float\n",
    "    # \t'''\n",
    "    # \t#### original data for new item ####\n",
    "    # \tnewitem_title_list = new_item['title']\n",
    "    # \tnewitem_description_list = new_item['description']\n",
    "    # \tnewitem_price_list = new_item['price']\n",
    "    # \t#### tf-idf result for new item ####\n",
    "    # \tnewitem_title_corpus = self.data_preprocess(newitem_title_list)\n",
    "    # \tnewitem_title_result = self.cal_tf_idf(newitem_title_corpus)\n",
    "    # \tnewitem_description_corpus = self.data_preprocess(newitem_description_list)\n",
    "    # \tnewitem_description_result = self.cal_tf_idf(newitem_description_corpus)\n",
    "    # \t#### price result for new item ####\n",
    "    # \tnewitem_price_list = new_item['price']\n",
    "    # \tprice_result = 2*(1.0 / (1+math.exp(-self.beta*(newitem_price_list[i]))))-1\n",
    "\n",
    "    # \treturn newitem_title_result[0], newitem_description_result[0], price_result\n",
    "\n",
    "\n",
    "    # def cal_cos_similarity(self, vec1, vec2):\n",
    "    # \t'''calculate cosine similarity between two vectors'''\n",
    "    # \tdot_product = 0.0\n",
    "    # \tnormA = 0.0\n",
    "    # \tnormB = 0.0\n",
    "    # \tfor a, b in zip(vec1, vec2):\n",
    "    # \t\tdot_product += a*b\n",
    "    # \t\tnormA += a**2\n",
    "    # \t\tnormB += b**2\n",
    "    # \tif normA == 0.0 or normB == 0.0:\n",
    "    # \t\treturn 0.0\n",
    "    # \telse:\n",
    "    # \t\treturn dot_product / ((normA*normB)**0.5)\n",
    "    def generate_topk_item_similarity(self, new_asin, k, target_user_list):\n",
    "            ''' return cosine similarity matrix\n",
    "            Input:\n",
    "                k: int value\n",
    "                new_asin: list\n",
    "            Output:\n",
    "                dict{ \n",
    "                    new_item1 : {\n",
    "                        '00001': 3\n",
    "                        '00002': 2\n",
    "                        '00003': 1\n",
    "                    }\n",
    "                    new_item2 : {\n",
    "                        '00004': 7\n",
    "                        '00005': 6\n",
    "                        '00006': 5\n",
    "                    }\t\n",
    "                    ...\n",
    "                }\n",
    "            '''\n",
    "            #### get the new&training dataset ####\n",
    "            '''dict {\n",
    "                        '0001': \n",
    "                            'title': []\n",
    "                            'description': []\n",
    "                            'price': float\n",
    "                        '0002':\n",
    "                            ...\n",
    "                    }\n",
    "            '''\n",
    "            if k > self.item_num:\n",
    "                k = self.item_num\n",
    "\n",
    "            train_item_vec_set = {n:self.data.loc[self.data['asin']==n].index[0] for n in target_user_list if n not in new_asin}\n",
    "            new_item_vec_set = {n:self.item_vector_set[n] for n in new_asin}\n",
    "\n",
    "            ret_k_similarities_dict = {}\n",
    "            for new_key, new_value in new_item_vec_set.items():\n",
    "                ret_k_similarities = []\n",
    "                for train_key, train_value in train_item_vec_set.items():\n",
    "                    value = self.item_vector_set[new_key]['title'][train_value] \\\n",
    "                                + self.alpha*self.item_vector_set[new_key]['description'][train_value] \\\n",
    "                                + self.theta*(np.abs(self.price_result[train_value]-new_value['price']))\n",
    "                    ret_k_similarities.append([value, train_key])\n",
    "                ret_k_similarities = sorted(ret_k_similarities, key=lambda x:x[0], reverse=True)\n",
    "                ret_k_similarities_dict_one = {ret_k_similarities[i][1]:ret_k_similarities[i][0] for i in range(len(ret_k_similarities)) if i <= k-1}\n",
    "                ret_k_similarities_dict[new_key] = ret_k_similarities_dict_one\n",
    "\n",
    "            return ret_k_similarities_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "import pandas as pd\n",
    "\n",
    "def parse(path):\n",
    "\tg = open(path, 'rb')\n",
    "\tfor l in g:\n",
    "\t\tyield eval(l)\n",
    "\n",
    "def getDF(path):\n",
    "\ti = 0\n",
    "\tdf = {}\n",
    "\tfor d in parse(path):\n",
    "\t\tdf[i] = d\n",
    "\t\ti += 1\n",
    "\treturn pd.DataFrame.from_dict(df, orient='index').loc[:, [\"title\", \"description\", \"price\", \"asin\"]]\n",
    "\n",
    "def Score(user_num, sim_set, rMatrix):\n",
    "\tsum_sim = 0\n",
    "\tsum_rate = 0\n",
    "\tratings_of_user = rMatrix[:,user_num].toarray().T.tolist()\n",
    "\tfor item_sim in sim_set:\n",
    "\t\tsum_sim += sim_set[item_sim]\n",
    "\t\tsum_rate += sim_set[item_sim] * ratings_of_user[0][item_sim]\n",
    "\treturn sum_rate/sum_sim\n",
    "\n",
    "def Probability(score):\n",
    "\treturn 1/(1 + math.exp(-score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Call CV function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def call_CV(simClass, mfClass, simItem_k, topUser_k, rMatrix_training, item_list, iteration1=10, iteration2=10, steplen_alpha=0.02, steplen_beta=2e-4, steplen_theta=-0.02):\n",
    "\n",
    "    #### Initial parameters and class ####\n",
    "    alpha, beta, theta = simClass.get_parameters()\n",
    "\n",
    "    aggr_output_of_cv = {}\n",
    "    #### parameter training iteration ####\n",
    "    for i in range(iteration1):\n",
    "        print(\"############################# %dth K-Cross Validation ###############################\"%(i))\n",
    "\n",
    "        #### Modify parameters for each iteration ####\n",
    "        alpha = alpha + steplen_alpha\n",
    "        beta = beta + steplen_beta\n",
    "        theta = theta + steplen_theta\n",
    "        simClass.change_parameters(alpha, beta, theta)\n",
    "\n",
    "        start = 0\n",
    "        end = int(rMatrix_training.shape[0]/iteration2)\n",
    "        RMSE = []\n",
    "        #### CV iteration ####\n",
    "        for j in range(iteration2):\n",
    "            print(\"---------- %dth fold of curent CV, %dth Iteration ----------\"%(j,i))\n",
    "            #print(\"%d-fold> \"%j)\n",
    "            #### Calculate the RMSE for this iteration ####\t\t    \n",
    "            RMSE.append(active_learning_process(simClass, mfClass, rMatrix_training, simItem_k, topUser_k, item_list, start, end))\n",
    "            print(\"RMSE: %f\"%RMSE[-1])\n",
    "            tmp = end\n",
    "            end = end + (end - start)\n",
    "            start = tmp\n",
    "\n",
    "\n",
    "        #### Caculate and record average RMESE for each iteration2 ####\n",
    "        aggr_output_of_cv[i] = {'avg_RMSE': sum(RMSE)/len(RMSE), 'alpha': alpha, 'beta': beta, 'theta': theta}\n",
    "        print(aggr_output_of_cv[i])\n",
    "\n",
    "    #### Find best RMSE and best parameters####\n",
    "    avg_rmse_lst = [aggr_output_of_cv[i]['avg_RMSE'] for i in aggr_output_of_cv]\n",
    "    index = avg_rmse_lst.index(max(avg_rmse_lst))\n",
    "\n",
    "    return aggr_output_of_cv, index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Active learning function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def active_learning_process(simClass, mfClass, rMatrix, simItem_k, topUser_k, item_list, start, end):\n",
    "\n",
    "    #### Split training set and validation set ####\t\n",
    "    rating_matrix_expanded = rMatrix.tolil()\n",
    "    rating_matrix_expanded[start:end,] = 0\n",
    "    print(\"rating_martix_expanded_CV DONE\")\n",
    "\n",
    "    #### find k similar items for each new item ####\n",
    "    newuser_asin = item_list[start:end]\t\t\n",
    "    print(\"test interval\")\n",
    "    print(start)\n",
    "    print(end)\n",
    "    sims = simClass.generate_topk_item_similarity(newuser_asin, simItem_k, item_list)\n",
    "\n",
    "    #### construct new-item similarity dictionary ####\n",
    "    '''\n",
    "        sims_indexed: {\n",
    "            'ITEM0001': {\n",
    "                'ITEM0005': s1\n",
    "                'ITEM0006': s2\n",
    "                ...\n",
    "            }\n",
    "            'ITEM0002': {\n",
    "                'ITEM0008': s3\n",
    "                ...\n",
    "            }\n",
    "            ...\n",
    "        }\n",
    "    '''\n",
    "    sims_indexed = {}\n",
    "    for item in sims:\n",
    "        sims_indexed[item] = {}\n",
    "        for item_sim in sims[item]:\n",
    "            sims_indexed[item][item_list.index(item_sim)] = sims[item][item_sim]\n",
    "    print(\"sims_indexed DONE\")\n",
    "    learned_ratings_list = []\n",
    "    #### Calculate Propability for each new item #### \n",
    "    for item in sims_indexed:    \n",
    "        user_probability = {}\n",
    "        sim_items_current = ()\n",
    "        for item_sim in sims_indexed[item]:\n",
    "            sim_items_current += (item_sim, )\n",
    "        users_rated_sims = sparse.find(rMatrix[sim_items_current,:])[1]\n",
    "        users_rated_sims = list(set(users_rated_sims))\n",
    "        for userNum in users_rated_sims:\n",
    "            user_probability[userNum] = Probability(Score(userNum, sims_indexed[item],rMatrix )) \n",
    "        user_probability = sorted(user_probability.items(), key=lambda d:d[1], reverse = True)\n",
    "\n",
    "        ### when related users are less than k, randomly fill users into top k users###\n",
    "        random_fill = True\n",
    "        if random_fill == True:\n",
    "            if(topUser_k > len(user_probability)):\n",
    "                while(len(user_probability) != topUser_k):\n",
    "                    filler = (int(rMatrix.shape[1] * random.random()), 0)\n",
    "                    for user_possible in user_probability:\n",
    "                        if filler[0] == user_possible[0]:\n",
    "                            filler = (int(rMatrix.shape[1] * random.random()), 0)\n",
    "                    user_probability.append(filler)\n",
    "\n",
    "        for top in range(topUser_k):    \n",
    "            rating_matrix_expanded[item_list.index(item), user_probability[top][0]] = \\\n",
    "                rMatrix[item_list.index(item), user_probability[top][0]]\n",
    "            learned_ratings_list.append((item_list.index(item), user_probability[top][0]))\n",
    "    print(\"item sims ALL DONE\")\n",
    "\n",
    "    ##### Caculate RMSE for each iteration2 #####\n",
    "    prMatrix = mfClass.MF_gradient_descent(rating_matrix_expanded)\n",
    "    print(\"matrix factorization DONE\")\n",
    "    RMSE = mfClass.calculate_average_RMSE(rMatrix, prMatrix, learned_ratings_list, start, end)\n",
    "    print(\"rmse DONE\")\n",
    "    return RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline 2.0.ipynb\n",
      "Baseline.ipynb\n",
      "item_metadata\n",
      "meta_All_Beauty.json\n",
      "meta_Amazon_Instant_Video.json\n",
      "meta_Cell_Phones_and_Accessories.json\n",
      "meta_Computers.json\n",
      "__pycache__\n",
      "ratings_Cell_Phones_and_Accessories.csv\n",
      "ratings_Computers.csv\n",
      "read_tool.py\n",
      "Spark test.ipynb\n",
      "Untitled.ipynb\n",
      "user_ratings\n",
      "\n"
     ]
    }
   ],
   "source": [
    "################################# 2017.10.14 #######################################\n",
    "''' Step 0: Import Package '''\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import math\n",
    "import random\n",
    "from subprocess import check_output\n",
    "from scipy.sparse import coo_matrix\n",
    "print(check_output([\"ls\", \".\"], shell=True).decode(\"utf8\"))\n",
    "#import tool_function as tf\n",
    "#from similarity import Similarity\n",
    "#from matrix_factorization import MatrixFactorization\n",
    "####################################################################################\n",
    "\n",
    "####################################################################################\n",
    "''' Step 1: Data Input '''\n",
    "#### Load in ratings data & meta_item data ####\n",
    "ratingsFrame = pd.read_csv('ratings_Grocery_and_Gourmet_Food.csv')\n",
    "itemsFrame = getDF('meta_Grocery_and_Gourmet_Food.json')\n",
    "####################################################################################\n",
    "\n",
    "####################################################################################\n",
    "''' Step 2: Data Process '''\n",
    "#### Fill out all the missing value ####\n",
    "itemsFrame['description'].fillna(\"\", inplace=True)\n",
    "itemsFrame['title'].fillna(\"\", inplace=True)\n",
    "itemsFrame['price'].fillna(0, inplace=True)\n",
    "#### drop items without any ratings ####\n",
    "for index, row in itemsFrame.iterrows():\n",
    "    if row[\"asin\"] not in ratingsFrame.loc[:,\"item\"].tolist():\n",
    "        itemsFrame.drop(index, inplace = True)\n",
    "itemsFrame.reset_index(drop=True, inplace = True)  \n",
    "itemsFrame = itemsFrame.sample(frac = 1, random_state = 1)\n",
    "# itemsFrame.head(3)\n",
    "# ratingsFrame.head(3)\n",
    "####################################################################################\n",
    "\n",
    "####################################################################################\n",
    "''' Step 3: Construct Item Dictionary \n",
    "\titems: \n",
    "\t\tdic {\n",
    "\t\t\t'B00001': {\n",
    "\t\t\t\t'User0001': r1\n",
    "\t\t\t\t'User0002': r2\n",
    "\t\t\t\t...\n",
    "\t\t\t}\n",
    "\t\t\t'B00002': {\n",
    "\t\t\t\t'User0003': r3\n",
    "\t\t\t\t'User0001': r4\n",
    "\t\t\t}\n",
    "\t\t\t...\n",
    "\t\t}\n",
    "'''\n",
    "items = {}  \n",
    "for num in range(itemsFrame.shape[0]):\n",
    "    items[itemsFrame.iloc[num][\"asin\"]] = {}\n",
    "for num in range(ratingsFrame.shape[0]):\n",
    "    if ratingsFrame.iloc[num][\"item\"] in items:  \n",
    "        items[ratingsFrame.iloc[num][\"item\"]][ratingsFrame.iloc[num][\"user\"]] = ratingsFrame.iloc[num][\"rating\"]\n",
    "####################################################################################\n",
    "\n",
    "####################################################################################\n",
    "''' Step 4: Construct User-Item Sparse Matrix '''\n",
    "user_list = []\n",
    "item_list = []\n",
    "row = []\n",
    "col = []\n",
    "rating_data = []\n",
    "itemNum = 0\n",
    "for item in items:\n",
    "    item_list.append(item)\n",
    "    for user in items[item]:\n",
    "        if user not in user_list:\n",
    "            user_list.append(user)\n",
    "        row.append(itemNum)\n",
    "        col.append(user_list.index(user))\n",
    "        rating_data.append(items[item][user])\n",
    "    itemNum += 1\n",
    "rating_martix_coo = coo_matrix((rating_data, (row, col)), shape=(itemsFrame.shape[0], len(user_list)))\n",
    "rating_martix_csc = rating_martix_coo.tocsc()\n",
    "rating_martix_csr = rating_martix_coo.tocsr()\n",
    "####################################################################################\n",
    "\n",
    "####################################################################################\n",
    "''' Step 5: Split Dataset into Training and Test'''\n",
    "start = 0\n",
    "end = int(rating_martix_csr.shape[0] * 0.7)\n",
    "rMatrix_training = rating_martix_csr[start:end,]\n",
    "#rMatrix_test set\n",
    "####################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CV part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "####################################################################################\n",
    "''' Step 6: Cross Validation '''\n",
    "simItem_k = 6             # top K similar item to the new item\n",
    "topUser_k = 3            # top K users to recommender the new item for ratings\n",
    "K = 20\t\t\t\t\t  # length of user profile and item profile when doing Matrix Factorization\n",
    "alpha = 1.0\n",
    "beta = 1e-3\n",
    "theta = -1.0\n",
    "simClass = Similarity(alpha, beta, theta)\n",
    "simClass.read_data(itemsFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################# 0th K-Cross Validation ###############################\n",
      "---------- 0th fold of curent CV, 0th Iteration ----------\n",
      "rating_martix_expanded_CV DONE\n",
      "test interval\n",
      "0\n",
      "298\n",
      "sims_indexed DONE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhaozihan/miniconda3/lib/python3.6/site-packages/ipykernel_launcher.py:24: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item sims ALL DONE\n",
      "MF iterations\n",
      "0\n",
      "35664.7637692\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZUAAAEWCAYAAACufwpNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f191346ec50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matrix factorization DONE\n",
      "rmse DONE\n",
      "RMSE: 1.980118\n",
      "---------- 1th fold of curent CV, 0th Iteration ----------\n",
      "rating_martix_expanded_CV DONE\n",
      "test interval\n",
      "298\n",
      "596\n",
      "sims_indexed DONE\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-26ba88a6e454>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmfClass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMatrixFactorization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptim_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_CV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msimClass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmfClass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msimItem_k\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopUser_k\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrMatrix_training\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m####################################################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-62574dfd91a7>\u001b[0m in \u001b[0;36mcall_CV\u001b[0;34m(simClass, mfClass, simItem_k, topUser_k, rMatrix_training, item_list, iteration1, iteration2, steplen_alpha, steplen_beta, steplen_theta)\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0;31m#print(\"%d-fold> \"%j)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;31m#### Calculate the RMSE for this iteration ####\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0mRMSE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactive_learning_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msimClass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmfClass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrMatrix_training\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msimItem_k\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopUser_k\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"RMSE: %f\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mRMSE\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-2cbe0106cb29>\u001b[0m in \u001b[0;36mactive_learning_process\u001b[0;34m(simClass, mfClass, rMatrix, simItem_k, topUser_k, item_list, start, end)\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0musers_rated_sims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0musers_rated_sims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0muserNum\u001b[0m \u001b[0;32min\u001b[0m \u001b[0musers_rated_sims\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m             \u001b[0muser_probability\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muserNum\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mProbability\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mScore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muserNum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msims_indexed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrMatrix\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m         \u001b[0muser_probability\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_probability\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-1b968cf1940d>\u001b[0m in \u001b[0;36mScore\u001b[0;34m(user_num, sim_set, rMatrix)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0msum_sim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0msum_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mratings_of_user\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrMatrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0muser_num\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mitem_sim\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msim_set\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m                 \u001b[0msum_sim\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0msim_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem_sim\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/scipy/sparse/csr.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    302\u001b[0m                      row.step in (1, None))):\n\u001b[1;32m    303\u001b[0m                 \u001b[0;31m# col is int or slice with step 1, row is slice with step 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_submatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0missequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 \u001b[0;31m# row is slice, col is sequence.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/scipy/sparse/csr.py\u001b[0m in \u001b[0;36m_get_submatrix\u001b[0;34m(self, row_slice, col_slice)\u001b[0m\n\u001b[1;32m    450\u001b[0m         indptr, indices, data = get_csr_submatrix(M, N,\n\u001b[1;32m    451\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindptr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 452\u001b[0;31m                 int(i0), int(i1), int(j0), int(j1))\n\u001b[0m\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m         \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mi0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mj0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mfClass = MatrixFactorization(K)\n",
    "model, optim_ind = call_CV(simClass, mfClass, simItem_k, topUser_k, rMatrix_training, item_list[start:end])\n",
    "####################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class MatrixFactorization:\n",
    "    def __init__(self, K, steps=100, alpha=0.006, beta=0.02, threshold=0.001):\n",
    "        # self.R = R                                     # user-item matrix\n",
    "        self.K = K                                     # feature number\n",
    "        self.steps = steps                             # iterate time\n",
    "        self.alpha = alpha                             # parameter1\n",
    "        self.beta = beta                               # parameter2\n",
    "        self.threshold = threshold                     # error threshold\n",
    "\n",
    "    def MF_gradient_descent(self, R):\n",
    "        self.P = np.random.rand(R.shape[1], self.K)         # user latent factor\n",
    "        self.Q = np.random.rand(R.shape[0], self.K)         # item latent factor \n",
    "        print(\"MF iterations\")\n",
    "        error_list = []\n",
    "        x = sparse.find(R)\n",
    "        row = x[0]\n",
    "        col = x[1]\n",
    "        for step in range(self.steps):\n",
    "            for i,j in zip(row, col):\n",
    "                eij = R[i,j] - np.dot(self.P[j, :], self.Q[i, :].T)\n",
    "                self.P[j, :] = self.P[j, :] + self.alpha * (2 * eij * self.Q[i, :] - self.beta * self.P[j, :])\n",
    "                self.Q[i, :] = self.Q[i, :] + self.alpha * (2 * eij * self.P[j, :] - self.beta * self.Q[i, :])\n",
    "            pR = np.dot(self.Q, self.P.T)\n",
    "            e = 0\n",
    "            for i,j in zip(row,col):\n",
    "                e = e + pow(R[i,j] - pR[i,j], 2)\n",
    "            for k in range(self.K):       # add regularization\n",
    "                e = e + (self.beta/2) * (pow(self.P[j][k], 2) + pow(self.Q[i][k], 2))\n",
    "            error_list.append(e)\n",
    "            if step % 10 == 0:\n",
    "                print(step)\n",
    "                print(e)\n",
    "            if e < self.threshold:\n",
    "                break\n",
    "\n",
    "        #### Plot RMSE picture ####\n",
    "        plt.figure(1) # 1\n",
    "        plt.title('loss for each iteration')\n",
    "        plt.xlabel('Iteration') \n",
    "        plt.ylabel('loss')\n",
    "        plt.plot(error_list)\n",
    "        plt.show()\n",
    "\n",
    "        return np.dot(self.Q, self.P.T)\n",
    "\n",
    "\n",
    "    def MF_ALS(self, R):\n",
    "        self.P = np.random.rand(R.shape[1], self.K)         # user latent factor\n",
    "        self.Q = np.random.rand(R.shape[0], self.K)         # item latent factor \n",
    "        print(\"MF iterations\")\n",
    "        error_list = []        \n",
    "        x = sparse.find(R)\n",
    "        row = x[0]                 # item\n",
    "        col = x[1]                 # user\n",
    "        for step in range(self.steps):\n",
    "            print(step)\n",
    "\n",
    "            #### User Part ####\n",
    "            denominatorV = 0\n",
    "            for i in range(R.shape[0]):\n",
    "                denominatorV = denominatorV + np.dot(self.Q[i, :], self.Q[i, :].T)\n",
    "            numeratorVR = np.zeros((R.shape[1], self.K))\n",
    "            for i,j in zip(row, col):\n",
    "                numeratorVR[j] = numeratorVR[j] + self.Q[i, :]*R[i, j]\n",
    "            self.P = numeratorVR / denominatorV\n",
    "\n",
    "            #### Item Part ####\n",
    "            denominatorU = 0\n",
    "            for i in range(R.shape[1]):\n",
    "                denominatorU = denominatorU + np.dot(self.P[i, :], self.P[i, :].T)\n",
    "            numeratorUR = np.zeros((R.shape[0], self.K))\n",
    "            for i,j in zip(row, col):\n",
    "                numeratorUR[i] = numeratorUR[i] + self.P[j, :]*R[i, j]\n",
    "            self.Q = numeratorUR / denominatorU\n",
    "\n",
    "            #### Calculate Predicted Matrix ####\n",
    "            pR = np.dot(self.Q, self.P.T)\n",
    "            e = 0\n",
    "            for i,j in zip(row,col):\n",
    "                e = e + pow(R[i,j] - pR[i,j], 2)\n",
    "            e = math.sqrt(e/len(row))\n",
    "            error_list.append(e)\n",
    "\n",
    "            #### Judge if small than threshold ###\n",
    "            if e < self.threshold:\n",
    "                break\n",
    "\n",
    "        #### Plot RMSE picture ####\n",
    "        plt.figure(1) # 1\n",
    "        plt.title('RMSE for each iteration')\n",
    "        plt.xlabel('Iteration') \n",
    "        plt.ylabel('RMSE value')\n",
    "        plt.plot(error_list)\n",
    "        plt.show()\n",
    "\n",
    "        return np.dot(self.Q, self.P.T)     \n",
    "\n",
    "    def calculate_average_RMSE(self, oRate, pRate, learned_ratings_list, start, end):\n",
    "        user_num = oRate.shape[1]\n",
    "        e = 0\n",
    "        cnt_of_rate = 0\n",
    "        \n",
    "        x = sparse.find(oRate)\n",
    "        row = x[0]\n",
    "        col = x[1]\n",
    "        for i,j in zip(row, col):\n",
    "            if i not in range(start, end):\n",
    "                continue\n",
    "            else:\n",
    "                if (i,j) not in learned_ratings_list:\n",
    "                    e = e + pow(oRate[i,j] - pRate[i,j], 2)\n",
    "                    cnt_of_rate = cnt_of_rate + 1\n",
    "        return math.sqrt(e/cnt_of_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "####################################################################################\n",
    "''' Step 7: Use Optimum Parameters on Test Datast''' \n",
    "start = int(rating_martix_csr.shape[0] * 0.7)\n",
    "end = rating_martix_csr.shape[0]\n",
    "alpha = model[optim_ind]['alpha']\n",
    "beta = model[optim_ind]['beta']\n",
    "theta = model[optim_ind]['theta']\n",
    "simClass.change_parameters(alpha, beta, theta)\n",
    "tRMSE = active_learning_process(simClass, mfClass, rating_martix_csr, simItem_k, topUser_k, item_list, start, end)\n",
    "####################################################################################\n",
    "\n",
    "####################################################################################\n",
    "''' Step 8: Plot Result of Baseline '''\n",
    "\n",
    "####################################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
